@[TOC](【NLP】【Prompt Tuning】PET （Pattern-Exploiting Training）方法介绍)


本文介绍**Prompt Tuning**方向的**PET**方法，论文标题为：**Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference**，来自EACL2021。
# 摘要
随着GPT3的出现，通过一些具有自然语言“任务描述”的预训练语言模型，可以以完全无监督的方式解决一些NLP任务。**PET**是一种==半监督==的训练方式，它首先将`input examples`转化为`cloze-style phrases`的形式以帮助模型理解给出的任务，之后利用这些`phrases`为一个更大的未标注的数据集分配`soft labels`，最后在该数据集上执行有监督训练。

# 介绍

 PET是一种半监督式训练程序，将任务描述与标准的监督学习相结合它使用自然语言`pattern`将`input examples`转化为`cloze-style phrases`。如下图所示，PET 分三步工作：
1. 针对每种`pattern`，在一个小的训练集  $\mathcal{T}$上对一个单独的PLM进行微调。
2. 使用所有PLM模型的集合为一个大的未标注数据集 $\mathcal{D}$ 添加`soft labels`。
3. 在这个`soft-labeled`的数据集上训练标准分类器。

![在这里插入图片描述](https://img-blog.csdnimg.cn/7933d2cd11ab4566b12680840ec27c27.png#pic_center)

作者还设计了 **iPET**，这是 PET 的一个迭代的变体，随着训练集大小的增加，这一过程会不断重复。

在多种语言的各种任务中，给定少量到中等数量的标注样本，PET 和 iPET 的表现大大优于无监督方法、有监督训练和强半监督基线。

# PET
- $M$ : masked LM
- $V$ : vocabulary
-  $\mathcal{L}$ : a set of labels
-  $\mathbf{x}$ : `input` as a sequence of phrases, $\mathbf{x}=\left(s_1,\ldots, s_k\right)$
- $P$ : ***pattern***，a function, $\mathbf{x}$ 为输入, $P(\mathbf{x}) \in V^*$ 为输出，是一个`phrase`或`sentence`, 其中包含有一个`mask` token。
- $v$：***verbalizer***，an injective function, $\mathcal{L} \rightarrow V$ 将每个标签映射到 $M$ 词汇表中的一个词。

将 $(P, v)$ 称为***pattern-verbalizer pair*** (PVP)。
## PVP Training and Inference
## Auxiliary Language Modeling
## Combining PVPs

## Iterative PET (iPET)
![在这里插入图片描述](https://img-blog.csdnimg.cn/df03849abb4b4c42aef8274e045807cc.png#pic_center)
PET (1-3) 和 iPET (a-c) 的示意图。
-  (**1**) 初始训练集$\mathcal{T}$用于微调 PLM 集合。 
- (**a**) 对于每个模型，其他模型的随机子集通过标记 $\mathcal{D}$ 中的样本来生成新的训练集。 
- (**b**) 使用更大的特定于模型的数据集来训练一组新的 PET 模型。 
- (**c**) 前两个步骤重复 $k$ 次，每次将生成的训练集的大小增加 $d$ 倍。
-  (**2**) 最终的模型集用于创建`soft-labeled`数据集 $\mathcal{T}_C$。
-  (**3**) 在此数据集上训练分类器 $C$。

**With minor adjustments, iPET can even be used in a zero-shot setting**

# 实验
**4 English datasets:**
- `Yelp Reviews`: the task is to estimate the rating that a customer gave to a restaurant on a 1- to 5-star scale based on their review’s text.
- `AG’s News`: is a news classification dataset, where given a headline a and text body b, news have to be classified as belonging to one of the categories *World (1)*, *Sports (2)*, *Business (3)* or *Science/Tech (4)*.
- `Yahoo Questions`: Given a question a and an answer b, one of ten possible categories has to be assigned: “Society”, “Science”, “Health”, “Education”, “Computer”, “Sports”, “Business”, “Entertainment”, “Relationship” and “Politics”.
- `MNLI `: consists of text pairs x = (a, b). The task is to find out whether a implies b (0), a and b contradict each other (1) or neither (2).

use `RoBERTa large`

**other languages:**
- `x-stance`: a multilingual stance detection  dataset with German, French and Italian examples.  Each example x = (a, b) consists of a question  a concerning some political issue and a comment  b; the task is to identify whether the writer of b supports the subject of the question (0) or not (1).

use `XLM-R`

# 结论
向预训练语言模型提供任务描述可以与标准的监督训练相结合。PET 包括的***pattern-verbalizer pair*** 帮助利用预训练语言模型中包含的知识来完成下游任务。利用PVP对模型进行微调，并使用它们来创建可以训练标准分类器的大型标注数据集。当初始训练数据有限时，PET 比标准监督训练和强大的半监督方法有很大提升。
